{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Week 4 - Day 3 Assignment\n",
        "\n",
        "Dataset: Spam email classifier (Kaggle)\n",
        "\n",
        "Tasks:\n",
        "- Train Random Forest model\n",
        "- Compare F1 score with a baseline model\n",
        "- Visualize feature importance\n",
        "- Optional: Train XGBoost and compare results\n"
      ],
      "id": "85bb8ae6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "4f27d69f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Update this path if your CSV has a different name\n",
        "candidate_paths = [\n",
        "    \"email_spam.csv\",  # common Kaggle file name\n",
        "    \"spam.csv\",        # fallback name used in other assignments\n",
        "]\n",
        "\n",
        "csv_path = next((p for p in candidate_paths if os.path.exists(p)), None)\n",
        "if csv_path is None:\n",
        "    raise FileNotFoundError(\n",
        "        \"Dataset not found. Place the Kaggle CSV in this folder and update candidate_paths.\"\n",
        "    )\n",
        "\n",
        "raw_df = pd.read_csv(csv_path)\n",
        "print(\"Loaded:\", csv_path)\n",
        "print(\"Columns:\", list(raw_df.columns))\n",
        "raw_df.head()"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "6115b2b5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Identify label and text columns (handles common Kaggle variants)\n",
        "label_candidates = [\"label\", \"category\", \"type\", \"spam\", \"v1\", \"class\"]\n",
        "text_candidates = [\"text\", \"message\", \"email\", \"v2\", \"content\", \"body\"]\n",
        "\n",
        "label_col = next((c for c in label_candidates if c in raw_df.columns), None)\n",
        "text_col = next((c for c in text_candidates if c in raw_df.columns), None)\n",
        "\n",
        "if label_col is None or text_col is None:\n",
        "    raise ValueError(\n",
        "        f\"Could not infer label/text columns. Found columns: {list(raw_df.columns)}\"\n",
        "    )\n",
        "\n",
        "# Clean and prepare\n",
        "_df = raw_df[[label_col, text_col]].copy()\n",
        "_df.columns = [\"label\", \"text\"]\n",
        "_df[\"text\"] = _df[\"text\"].astype(str)\n",
        "\n",
        "# Map labels to binary (spam=1, ham=0)\n",
        "label_map = {\n",
        "    \"spam\": 1,\n",
        "    \"ham\": 0,\n",
        "    \"not spam\": 0,\n",
        "    \"non-spam\": 0,\n",
        "    \"legit\": 0,\n",
        "}\n",
        "\n",
        "if _df[\"label\"].dtype == object:\n",
        "    _df[\"label\"] = _df[\"label\"].str.strip().str.lower().map(label_map)\n",
        "\n",
        "# If already numeric, coerce to int\n",
        "_df[\"label\"] = pd.to_numeric(_df[\"label\"], errors=\"coerce\")\n",
        "_df = _df.dropna(subset=[\"label\", \"text\"])\n",
        "_df[\"label\"] = _df[\"label\"].astype(int)\n",
        "\n",
        "print(_df[\"label\"].value_counts())\n",
        "_df.head()"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "1d0af156"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    _df[\"text\"], _df[\"label\"], test_size=0.2, random_state=42, stratify=_df[\"label\"]\n",
        ")\n",
        "\n",
        "# Baseline model: Logistic Regression\n",
        "baseline = Pipeline([\n",
        "    (\"tfidf\", TfidfVectorizer(stop_words=\"english\", max_features=5000)),\n",
        "    (\"clf\", LogisticRegression(max_iter=1000))\n",
        "])\n",
        "\n",
        "baseline.fit(X_train, y_train)\n",
        "baseline_preds = baseline.predict(X_test)\n",
        "\n",
        "baseline_f1 = f1_score(y_test, baseline_preds)\n",
        "baseline_acc = accuracy_score(y_test, baseline_preds)\n",
        "\n",
        "print(f\"Baseline (LogReg) F1: {baseline_f1:.4f}\")\n",
        "print(f\"Baseline (LogReg) Acc: {baseline_acc:.4f}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "34bffd66"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Random Forest model\n",
        "rf = Pipeline([\n",
        "    (\"tfidf\", TfidfVectorizer(stop_words=\"english\", max_features=5000)),\n",
        "    (\"clf\", RandomForestClassifier(\n",
        "        n_estimators=200,\n",
        "        random_state=42,\n",
        "        n_jobs=-1,\n",
        "        class_weight=\"balanced\"\n",
        "    ))\n",
        "])\n",
        "\n",
        "rf.fit(X_train, y_train)\n",
        "rf_preds = rf.predict(X_test)\n",
        "\n",
        "rf_f1 = f1_score(y_test, rf_preds)\n",
        "rf_acc = accuracy_score(y_test, rf_preds)\n",
        "\n",
        "print(f\"Random Forest F1: {rf_f1:.4f}\")\n",
        "print(f\"Random Forest Acc: {rf_acc:.4f}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "9a4bd809"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Compare results\n",
        "comparison = pd.DataFrame({\n",
        "    \"Model\": [\"Logistic Regression\", \"Random Forest\"],\n",
        "    \"F1\": [baseline_f1, rf_f1],\n",
        "    \"Accuracy\": [baseline_acc, rf_acc]\n",
        "})\n",
        "comparison"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "d69f5043"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Feature importance from Random Forest\n",
        "vectorizer = rf.named_steps[\"tfidf\"]\n",
        "rf_model = rf.named_steps[\"clf\"]\n",
        "\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "importances = rf_model.feature_importances_\n",
        "\n",
        "# Top 20 important features\n",
        "indices = np.argsort(importances)[-20:]\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.barh(range(len(indices)), importances[indices], color=\"teal\")\n",
        "plt.yticks(range(len(indices)), feature_names[indices])\n",
        "plt.title(\"Top 20 Feature Importances (Random Forest)\")\n",
        "plt.xlabel(\"Importance\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "22471642"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Optional: XGBoost model\n",
        "try:\n",
        "    from xgboost import XGBClassifier\n",
        "\n",
        "    xgb = Pipeline([\n",
        "        (\"tfidf\", TfidfVectorizer(stop_words=\"english\", max_features=5000)),\n",
        "        (\"clf\", XGBClassifier(\n",
        "            n_estimators=300,\n",
        "            learning_rate=0.1,\n",
        "            max_depth=6,\n",
        "            subsample=0.9,\n",
        "            colsample_bytree=0.9,\n",
        "            random_state=42,\n",
        "            eval_metric=\"logloss\"\n",
        "        ))\n",
        "    ])\n",
        "\n",
        "    xgb.fit(X_train, y_train)\n",
        "    xgb_preds = xgb.predict(X_test)\n",
        "\n",
        "    xgb_f1 = f1_score(y_test, xgb_preds)\n",
        "    xgb_acc = accuracy_score(y_test, xgb_preds)\n",
        "\n",
        "    print(f\"XGBoost F1: {xgb_f1:.4f}\")\n",
        "    print(f\"XGBoost Acc: {xgb_acc:.4f}\")\n",
        "except Exception as e:\n",
        "    print(\"XGBoost not run:\", e)"
      ],
      "id": "178ca5e8",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}