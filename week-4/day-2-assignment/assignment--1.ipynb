{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3521e624-4a87-4bfa-a998-02f9de4bcf21",
   "metadata": {},
   "outputs": [],
   "source": [
    " #PART 1: HOUSE PRICE PREDICTION (REGRESSION)\n",
    "#Import Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72946f34-c663-4dcd-93f5-db9ee47377d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>area</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>stories</th>\n",
       "      <th>mainroad</th>\n",
       "      <th>guestroom</th>\n",
       "      <th>basement</th>\n",
       "      <th>hotwaterheating</th>\n",
       "      <th>airconditioning</th>\n",
       "      <th>parking</th>\n",
       "      <th>prefarea</th>\n",
       "      <th>furnishingstatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13300000</td>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12250000</td>\n",
       "      <td>8960</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12250000</td>\n",
       "      <td>9960</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>semi-furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12215000</td>\n",
       "      <td>7500</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11410000</td>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price  area  bedrooms  bathrooms  stories mainroad guestroom basement  \\\n",
       "0  13300000  7420         4          2        3      yes        no       no   \n",
       "1  12250000  8960         4          4        4      yes        no       no   \n",
       "2  12250000  9960         3          2        2      yes        no      yes   \n",
       "3  12215000  7500         4          2        2      yes        no      yes   \n",
       "4  11410000  7420         4          1        2      yes       yes      yes   \n",
       "\n",
       "  hotwaterheating airconditioning  parking prefarea furnishingstatus  \n",
       "0              no             yes        2      yes        furnished  \n",
       "1              no             yes        3       no        furnished  \n",
       "2              no              no        2      yes   semi-furnished  \n",
       "3              no             yes        3      yes        furnished  \n",
       "4              no             yes        2       no        furnished  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Housing Dataset\n",
    "import pandas as pd\n",
    "df = pd.read_csv(r\"C:\\Users\\Malli Mounika\\Downloads\\Housing1.csv\")  \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8233885f-d9b2-4acf-94f3-c9b28e0fd6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split Done Successfully \n"
     ]
    }
   ],
   "source": [
    "#Data Preprocessing\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Drop missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Separate features & target\n",
    "X = df.drop(\"price\", axis=1)\n",
    "y = df[\"price\"]\n",
    "\n",
    "# Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Split Done Successfully \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dbd7e3a3-fb7f-4c21-8f4e-77fa5d2344d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Convert ALL categorical columns automatically\n",
    "df = pd.get_dummies(df, drop_first=True)\n",
    "\n",
    "# Separate features & target\n",
    "X = df.drop(\"price\", axis=1)\n",
    "y = df[\"price\"]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed3eb69e-523a-43a3-9efa-2a6360f61bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Trained Successfully \n",
      "MAE: 970043.403920164\n",
      "MSE: 1754318687330.6643\n",
      "RMSE: 1324506.9600914388\n",
      "R2 Score: 0.6529242642153184\n"
     ]
    }
   ],
   "source": [
    "#Train Model (without scaling)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Model Trained Successfully \")\n",
    "\n",
    "print(\"MAE:\", mean_absolute_error(y_test, y_pred))\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "print(\"R2 Score:\", r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01ad0e7e-5a9a-4e7f-bb64-fed4af39b4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b6cded0-8533-4e9f-b1c8-72ee956f9569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Trained After Scaling \n"
     ]
    }
   ],
   "source": [
    "#Train Model AFTER Scaling\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model_scaled = LinearRegression()\n",
    "model_scaled.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_scaled = model_scaled.predict(X_test_scaled)\n",
    "\n",
    "print(\"Model Trained After Scaling \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5071f4f-5d1e-49e3-a0b6-5011be3e738b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Malli Mounika\\AppData\\Local\\Temp\\ipykernel_14940\\466279336.py:6: DtypeWarning: Columns (10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  spam_df = pd.read_csv(r\"C:\\Users\\Malli Mounika\\Downloads\\completeSpamAssassin1.csv\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Body</th>\n",
       "      <th>Label</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 36</th>\n",
       "      <th>Unnamed: 37</th>\n",
       "      <th>Unnamed: 38</th>\n",
       "      <th>Unnamed: 39</th>\n",
       "      <th>Unnamed: 40</th>\n",
       "      <th>Unnamed: 41</th>\n",
       "      <th>Unnamed: 42</th>\n",
       "      <th>Unnamed: 43</th>\n",
       "      <th>Unnamed: 44</th>\n",
       "      <th>Unnamed: 45</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>\\nSave up to 70% on Life Insurance.\\nWhy Spend...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1) Fight The Risk of Cancer!\\nhttp://www.adcli...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1) Fight The Risk of Cancer!\\nhttp://www.adcli...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>##############################################...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>I thought you might like these:\\n1) Slim Down ...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22411</th>\n",
       "      <td>registered with the U.S. Library of Congress I...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22412</th>\n",
       "      <td>---</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22413</th>\n",
       "      <td>You are currently subscribed to neatnettricks ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22414</th>\n",
       "      <td>To unsubscribe send a blank email to leave-nea...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22415</th>\n",
       "      <td>,0\\n6044,empty,0\\n6045,empty,0\\n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22416 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Unnamed: 0  \\\n",
       "0                                                      0   \n",
       "1                                                      1   \n",
       "2                                                      2   \n",
       "3                                                      3   \n",
       "4                                                      4   \n",
       "...                                                  ...   \n",
       "22411  registered with the U.S. Library of Congress I...   \n",
       "22412                                                ---   \n",
       "22413  You are currently subscribed to neatnettricks ...   \n",
       "22414  To unsubscribe send a blank email to leave-nea...   \n",
       "22415                   ,0\\n6044,empty,0\\n6045,empty,0\\n   \n",
       "\n",
       "                                                    Body Label Unnamed: 3  \\\n",
       "0      \\nSave up to 70% on Life Insurance.\\nWhy Spend...     1        NaN   \n",
       "1      1) Fight The Risk of Cancer!\\nhttp://www.adcli...     1        NaN   \n",
       "2      1) Fight The Risk of Cancer!\\nhttp://www.adcli...     1        NaN   \n",
       "3      ##############################################...     1        NaN   \n",
       "4      I thought you might like these:\\n1) Slim Down ...     1        NaN   \n",
       "...                                                  ...   ...        ...   \n",
       "22411                                                NaN   NaN        NaN   \n",
       "22412                                                NaN   NaN        NaN   \n",
       "22413                                                NaN   NaN        NaN   \n",
       "22414                                                NaN   NaN        NaN   \n",
       "22415                                                NaN   NaN        NaN   \n",
       "\n",
       "      Unnamed: 4 Unnamed: 5 Unnamed: 6 Unnamed: 7 Unnamed: 8 Unnamed: 9  ...  \\\n",
       "0            NaN        NaN        NaN        NaN        NaN        NaN  ...   \n",
       "1            NaN        NaN        NaN        NaN        NaN        NaN  ...   \n",
       "2            NaN        NaN        NaN        NaN        NaN        NaN  ...   \n",
       "3            NaN        NaN        NaN        NaN        NaN        NaN  ...   \n",
       "4            NaN        NaN        NaN        NaN        NaN        NaN  ...   \n",
       "...          ...        ...        ...        ...        ...        ...  ...   \n",
       "22411        NaN        NaN        NaN        NaN        NaN        NaN  ...   \n",
       "22412        NaN        NaN        NaN        NaN        NaN        NaN  ...   \n",
       "22413        NaN        NaN        NaN        NaN        NaN        NaN  ...   \n",
       "22414        NaN        NaN        NaN        NaN        NaN        NaN  ...   \n",
       "22415        NaN        NaN        NaN        NaN        NaN        NaN  ...   \n",
       "\n",
       "      Unnamed: 36 Unnamed: 37 Unnamed: 38 Unnamed: 39 Unnamed: 40 Unnamed: 41  \\\n",
       "0             NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "1             NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "2             NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "3             NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "4             NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "...           ...         ...         ...         ...         ...         ...   \n",
       "22411         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "22412         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "22413         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "22414         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "22415         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "      Unnamed: 42 Unnamed: 43 Unnamed: 44 Unnamed: 45  \n",
       "0             NaN         NaN         NaN         NaN  \n",
       "1             NaN         NaN         NaN         NaN  \n",
       "2             NaN         NaN         NaN         NaN  \n",
       "3             NaN         NaN         NaN         NaN  \n",
       "4             NaN         NaN         NaN         NaN  \n",
       "...           ...         ...         ...         ...  \n",
       "22411         NaN         NaN         NaN         NaN  \n",
       "22412         NaN         NaN         NaN         NaN  \n",
       "22413         NaN         NaN         NaN         NaN  \n",
       "22414         NaN         NaN         NaN         NaN  \n",
       "22415         NaN         NaN         NaN         NaN  \n",
       "\n",
       "[22416 rows x 46 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#PART 2: EMAIL SPAM DETECTION (CLASSIFICATION)\n",
    "#Import Required Libraries\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "spam_df = pd.read_csv(r\"C:\\Users\\Malli Mounika\\Downloads\\completeSpamAssassin1.csv\")  \n",
    "\n",
    "spam_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a68db1a5-e1e2-4651-81e3-1ebab8bf27fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Body</th>\n",
       "      <th>Label</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 36</th>\n",
       "      <th>Unnamed: 37</th>\n",
       "      <th>Unnamed: 38</th>\n",
       "      <th>Unnamed: 39</th>\n",
       "      <th>Unnamed: 40</th>\n",
       "      <th>Unnamed: 41</th>\n",
       "      <th>Unnamed: 42</th>\n",
       "      <th>Unnamed: 43</th>\n",
       "      <th>Unnamed: 44</th>\n",
       "      <th>Unnamed: 45</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>\\nSave up to 70% on Life Insurance.\\nWhy Spend...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1) Fight The Risk of Cancer!\\nhttp://www.adcli...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1) Fight The Risk of Cancer!\\nhttp://www.adcli...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>##############################################...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>I thought you might like these:\\n1) Slim Down ...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0                                               Body Label  \\\n",
       "0          0  \\nSave up to 70% on Life Insurance.\\nWhy Spend...     1   \n",
       "1          1  1) Fight The Risk of Cancer!\\nhttp://www.adcli...     1   \n",
       "2          2  1) Fight The Risk of Cancer!\\nhttp://www.adcli...     1   \n",
       "3          3  ##############################################...     1   \n",
       "4          4  I thought you might like these:\\n1) Slim Down ...     1   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4 Unnamed: 5 Unnamed: 6 Unnamed: 7 Unnamed: 8  \\\n",
       "0        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "1        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "2        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "3        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "4        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "\n",
       "  Unnamed: 9  ... Unnamed: 36 Unnamed: 37 Unnamed: 38 Unnamed: 39 Unnamed: 40  \\\n",
       "0        NaN  ...         NaN         NaN         NaN         NaN         NaN   \n",
       "1        NaN  ...         NaN         NaN         NaN         NaN         NaN   \n",
       "2        NaN  ...         NaN         NaN         NaN         NaN         NaN   \n",
       "3        NaN  ...         NaN         NaN         NaN         NaN         NaN   \n",
       "4        NaN  ...         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "  Unnamed: 41 Unnamed: 42 Unnamed: 43 Unnamed: 44 Unnamed: 45  \n",
       "0         NaN         NaN         NaN         NaN         NaN  \n",
       "1         NaN         NaN         NaN         NaN         NaN  \n",
       "2         NaN         NaN         NaN         NaN         NaN  \n",
       "3         NaN         NaN         NaN         NaN         NaN  \n",
       "4         NaN         NaN         NaN         NaN         NaN  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b2192235-6bf8-43a9-b222-657b21dc193e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Scaling:\n",
      "Accuracy: 0.009174311926605505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     1750000       0.00      0.00      0.00         1\n",
      "     1820000       0.00      0.00      0.00         1\n",
      "     1890000       0.00      0.00      0.00         2\n",
      "     2100000       0.00      0.00      0.00         1\n",
      "     2233000       0.00      0.00      0.00         1\n",
      "     2275000       0.00      0.00      0.00         1\n",
      "     2380000       0.00      0.00      0.00         1\n",
      "     2450000       0.00      0.00      0.00         2\n",
      "     2520000       0.00      0.00      0.00         1\n",
      "     2660000       0.00      0.00      0.00         4\n",
      "     2800000       0.00      0.00      0.00         1\n",
      "     2870000       0.00      0.00      0.00         1\n",
      "     2940000       0.00      0.00      0.00         2\n",
      "     3003000       0.00      0.00      0.00         1\n",
      "     3010000       0.00      0.00      0.00         1\n",
      "     3045000       0.00      0.00      0.00         1\n",
      "     3080000       0.00      0.00      0.00         2\n",
      "     3150000       0.00      0.00      0.00         1\n",
      "     3220000       0.00      0.00      0.00         1\n",
      "     3234000       0.00      0.00      0.00         1\n",
      "     3290000       0.00      0.00      0.00         1\n",
      "     3325000       0.00      0.00      0.00         1\n",
      "     3353000       0.00      0.00      0.00         1\n",
      "     3360000       0.00      0.00      0.00         2\n",
      "     3430000       0.00      0.00      0.00         0\n",
      "     3500000       0.00      0.00      0.00         3\n",
      "     3640000       0.00      0.00      0.00         1\n",
      "     3675000       0.00      0.00      0.00         1\n",
      "     3703000       0.00      0.00      0.00         1\n",
      "     3710000       0.00      0.00      0.00         1\n",
      "     3773000       0.00      0.00      0.00         1\n",
      "     3780000       0.00      0.00      0.00         1\n",
      "     3850000       0.00      0.00      0.00         1\n",
      "     3920000       0.00      0.00      0.00         0\n",
      "     4007500       0.00      0.00      0.00         1\n",
      "     4025000       0.00      0.00      0.00         0\n",
      "     4060000       0.00      0.00      0.00         1\n",
      "     4165000       0.00      0.00      0.00         1\n",
      "     4193000       0.00      0.00      0.00         2\n",
      "     4200000       0.03      1.00      0.07         1\n",
      "     4270000       0.00      0.00      0.00         1\n",
      "     4340000       0.00      0.00      0.00         2\n",
      "     4480000       0.00      0.00      0.00         1\n",
      "     4543000       0.00      0.00      0.00         1\n",
      "     4550000       0.00      0.00      0.00         2\n",
      "     4620000       0.00      0.00      0.00         0\n",
      "     4690000       0.00      0.00      0.00         1\n",
      "     4753000       0.00      0.00      0.00         1\n",
      "     4760000       0.00      0.00      0.00         0\n",
      "     4830000       0.00      0.00      0.00         1\n",
      "     4900000       0.00      0.00      0.00         3\n",
      "     4907000       0.00      0.00      0.00         1\n",
      "     5110000       0.00      0.00      0.00         2\n",
      "     5145000       0.00      0.00      0.00         1\n",
      "     5250000       0.00      0.00      0.00         2\n",
      "     5425000       0.00      0.00      0.00         1\n",
      "     5460000       0.00      0.00      0.00         0\n",
      "     5495000       0.00      0.00      0.00         1\n",
      "     5530000       0.00      0.00      0.00         2\n",
      "     5600000       0.00      0.00      0.00         2\n",
      "     5740000       0.00      0.00      0.00         2\n",
      "     5810000       0.00      0.00      0.00         1\n",
      "     5950000       0.00      0.00      0.00         1\n",
      "     6195000       0.00      0.00      0.00         1\n",
      "     6230000       0.00      0.00      0.00         1\n",
      "     6300000       0.00      0.00      0.00         0\n",
      "     6440000       0.00      0.00      0.00         2\n",
      "     6510000       0.00      0.00      0.00         2\n",
      "     6580000       0.00      0.00      0.00         1\n",
      "     6615000       0.00      0.00      0.00         1\n",
      "     6650000       0.00      0.00      0.00         5\n",
      "     6685000       0.00      0.00      0.00         1\n",
      "     6720000       0.00      0.00      0.00         1\n",
      "     6790000       0.00      0.00      0.00         1\n",
      "     6860000       0.00      0.00      0.00         1\n",
      "     7035000       0.00      0.00      0.00         1\n",
      "     7350000       0.00      0.00      0.00         2\n",
      "     7420000       0.00      0.00      0.00         0\n",
      "     7700000       0.00      0.00      0.00         0\n",
      "     7910000       0.00      0.00      0.00         1\n",
      "     8190000       0.00      0.00      0.00         1\n",
      "     8400000       0.00      0.00      0.00         1\n",
      "     8645000       0.00      0.00      0.00         1\n",
      "     8890000       0.00      0.00      0.00         1\n",
      "     9100000       0.00      0.00      0.00         1\n",
      "     9681000       0.00      0.00      0.00         1\n",
      "     9800000       0.00      0.00      0.00         2\n",
      "    10150000       0.00      0.00      0.00         1\n",
      "    12250000       0.00      0.00      0.00         1\n",
      "    13300000       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.01       109\n",
      "   macro avg       0.00      0.01      0.00       109\n",
      "weighted avg       0.00      0.01      0.00       109\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Malli Mounika\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:406: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Malli Mounika\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\Malli Mounika\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\Malli Mounika\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\Malli Mounika\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\Malli Mounika\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\Malli Mounika\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "#Train WITHOUT Scaling\n",
    "log_model = LogisticRegression(max_iter=1000)\n",
    "log_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = log_model.predict(X_test)\n",
    "\n",
    "print(\"Before Scaling:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b5a7c4ff-082b-4200-95b8-10f8dd4bf5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply Scaling\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6d7ca26f-8d04-416e-9ddc-bd7e992d1e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After Scaling:\n",
      "Accuracy: 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     1750000       0.00      0.00      0.00       1.0\n",
      "     1820000       0.00      0.00      0.00       1.0\n",
      "     1890000       0.00      0.00      0.00       2.0\n",
      "     2100000       0.00      0.00      0.00       1.0\n",
      "     2233000       0.00      0.00      0.00       1.0\n",
      "     2275000       0.00      0.00      0.00       1.0\n",
      "     2380000       0.00      0.00      0.00       1.0\n",
      "     2450000       0.00      0.00      0.00       2.0\n",
      "     2520000       0.00      0.00      0.00       1.0\n",
      "     2653000       0.00      0.00      0.00       0.0\n",
      "     2660000       0.00      0.00      0.00       4.0\n",
      "     2800000       0.00      0.00      0.00       1.0\n",
      "     2870000       0.00      0.00      0.00       1.0\n",
      "     2940000       0.00      0.00      0.00       2.0\n",
      "     3003000       0.00      0.00      0.00       1.0\n",
      "     3010000       0.00      0.00      0.00       1.0\n",
      "     3045000       0.00      0.00      0.00       1.0\n",
      "     3080000       0.00      0.00      0.00       2.0\n",
      "     3115000       0.00      0.00      0.00       0.0\n",
      "     3150000       0.00      0.00      0.00       1.0\n",
      "     3220000       0.00      0.00      0.00       1.0\n",
      "     3234000       0.00      0.00      0.00       1.0\n",
      "     3290000       0.00      0.00      0.00       1.0\n",
      "     3325000       0.00      0.00      0.00       1.0\n",
      "     3353000       0.00      0.00      0.00       1.0\n",
      "     3360000       0.00      0.00      0.00       2.0\n",
      "     3430000       0.00      0.00      0.00       0.0\n",
      "     3500000       0.00      0.00      0.00       3.0\n",
      "     3640000       0.00      0.00      0.00       1.0\n",
      "     3675000       0.00      0.00      0.00       1.0\n",
      "     3703000       0.00      0.00      0.00       1.0\n",
      "     3710000       0.00      0.00      0.00       1.0\n",
      "     3773000       0.00      0.00      0.00       1.0\n",
      "     3780000       0.00      0.00      0.00       1.0\n",
      "     3850000       0.00      0.00      0.00       1.0\n",
      "     3885000       0.00      0.00      0.00       0.0\n",
      "     3920000       0.00      0.00      0.00       0.0\n",
      "     3990000       0.00      0.00      0.00       0.0\n",
      "     4007500       0.00      0.00      0.00       1.0\n",
      "     4060000       0.00      0.00      0.00       1.0\n",
      "     4095000       0.00      0.00      0.00       0.0\n",
      "     4165000       0.00      0.00      0.00       1.0\n",
      "     4193000       0.00      0.00      0.00       2.0\n",
      "     4200000       0.00      0.00      0.00       1.0\n",
      "     4270000       0.00      0.00      0.00       1.0\n",
      "     4340000       0.00      0.00      0.00       2.0\n",
      "     4480000       0.00      0.00      0.00       1.0\n",
      "     4515000       0.00      0.00      0.00       0.0\n",
      "     4543000       0.00      0.00      0.00       1.0\n",
      "     4550000       0.00      0.00      0.00       2.0\n",
      "     4620000       0.00      0.00      0.00       0.0\n",
      "     4690000       0.00      0.00      0.00       1.0\n",
      "     4753000       0.00      0.00      0.00       1.0\n",
      "     4760000       0.00      0.00      0.00       0.0\n",
      "     4795000       0.00      0.00      0.00       0.0\n",
      "     4830000       0.00      0.00      0.00       1.0\n",
      "     4900000       0.00      0.00      0.00       3.0\n",
      "     4907000       0.00      0.00      0.00       1.0\n",
      "     4970000       0.00      0.00      0.00       0.0\n",
      "     5110000       0.00      0.00      0.00       2.0\n",
      "     5145000       0.00      0.00      0.00       1.0\n",
      "     5250000       0.00      0.00      0.00       2.0\n",
      "     5425000       0.00      0.00      0.00       1.0\n",
      "     5460000       0.00      0.00      0.00       0.0\n",
      "     5495000       0.00      0.00      0.00       1.0\n",
      "     5530000       0.00      0.00      0.00       2.0\n",
      "     5600000       0.00      0.00      0.00       2.0\n",
      "     5740000       0.00      0.00      0.00       2.0\n",
      "     5775000       0.00      0.00      0.00       0.0\n",
      "     5810000       0.00      0.00      0.00       1.0\n",
      "     5950000       0.00      0.00      0.00       1.0\n",
      "     6020000       0.00      0.00      0.00       0.0\n",
      "     6083000       0.00      0.00      0.00       0.0\n",
      "     6125000       0.00      0.00      0.00       0.0\n",
      "     6160000       0.00      0.00      0.00       0.0\n",
      "     6195000       0.00      0.00      0.00       1.0\n",
      "     6230000       0.00      0.00      0.00       1.0\n",
      "     6265000       0.00      0.00      0.00       0.0\n",
      "     6300000       0.00      0.00      0.00       0.0\n",
      "     6440000       0.00      0.00      0.00       2.0\n",
      "     6510000       0.00      0.00      0.00       2.0\n",
      "     6580000       0.00      0.00      0.00       1.0\n",
      "     6615000       0.00      0.00      0.00       1.0\n",
      "     6650000       0.00      0.00      0.00       5.0\n",
      "     6685000       0.00      0.00      0.00       1.0\n",
      "     6720000       0.00      0.00      0.00       1.0\n",
      "     6790000       0.00      0.00      0.00       1.0\n",
      "     6860000       0.00      0.00      0.00       1.0\n",
      "     7035000       0.00      0.00      0.00       1.0\n",
      "     7070000       0.00      0.00      0.00       0.0\n",
      "     7350000       0.00      0.00      0.00       2.0\n",
      "     7420000       0.00      0.00      0.00       0.0\n",
      "     7455000       0.00      0.00      0.00       0.0\n",
      "     7560000       0.00      0.00      0.00       0.0\n",
      "     7700000       0.00      0.00      0.00       0.0\n",
      "     7840000       0.00      0.00      0.00       0.0\n",
      "     7910000       0.00      0.00      0.00       1.0\n",
      "     8190000       0.00      0.00      0.00       1.0\n",
      "     8295000       0.00      0.00      0.00       0.0\n",
      "     8400000       0.00      0.00      0.00       1.0\n",
      "     8645000       0.00      0.00      0.00       1.0\n",
      "     8890000       0.00      0.00      0.00       1.0\n",
      "     9100000       0.00      0.00      0.00       1.0\n",
      "     9240000       0.00      0.00      0.00       0.0\n",
      "     9681000       0.00      0.00      0.00       1.0\n",
      "     9800000       0.00      0.00      0.00       2.0\n",
      "    10150000       0.00      0.00      0.00       1.0\n",
      "    12250000       0.00      0.00      0.00       1.0\n",
      "    13300000       0.00      0.00      0.00       1.0\n",
      "\n",
      "    accuracy                           0.00     109.0\n",
      "   macro avg       0.00      0.00      0.00     109.0\n",
      "weighted avg       0.00      0.00      0.00     109.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Malli Mounika\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\Malli Mounika\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\Malli Mounika\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\Malli Mounika\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\Malli Mounika\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\Malli Mounika\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "#Train AFTER Scaling\n",
    "\n",
    "log_model_scaled = LogisticRegression(max_iter=1000)\n",
    "log_model_scaled.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_scaled = log_model_scaled.predict(X_test_scaled)\n",
    "\n",
    "print(\"\\nAfter Scaling:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_scaled))\n",
    "print(classification_report(y_test, y_pred_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1fcfa0-6473-4677-9e3f-1e29bb3e7e17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
