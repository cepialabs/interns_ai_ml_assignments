# ğŸ  House Prices Prediction (Random Forest + Feature Importance)

This project predicts **house prices** using Machine Learning regression models.
It trains a **Random Forest Regressor** and compares its performance (RÂ² score) with previous models.
It also visualizes **feature importance** to understand which features affect predictions the most.

---

## ğŸ“Œ Dataset

**File:** `house_prices.csv`

### Columns
| Feature Columns | Description |
|---|---|
| age | Age feature |
| sex | Gender feature |
| bmi | Body Mass Index |
| bp | Blood pressure |
| s1 - s6 | Other numerical health-related features |

### Target Column
| Column | Meaning |
|---|---|
| price | Predicted output value |

---

## ğŸ¯ Objective

- Train a **Random Forest Regression** model  
- Compare **RÂ² score** with previous models  
- Visualize **Feature Importance**
- (Optional) Train **XGBoost Regressor** and compare results

---

## ğŸ› ï¸ Libraries Used

- pandas  
- numpy  
- matplotlib  
- scikit-learn  
- xgboost (optional)

---

## âš™ï¸ Steps Performed

### 1ï¸âƒ£ Load the dataset
- Loaded `house_prices.csv`
- Checked dataset shape, columns, and missing values

### 2ï¸âƒ£ Train-Test Split
- Split the dataset into:
  - 80% training data
  - 20% testing data

### 3ï¸âƒ£ Train Random Forest Model
- Trained a `RandomForestRegressor` using the training data

### 4ï¸âƒ£ Evaluate Performance
- Used **RÂ² Score** for model evaluation
- Also calculated **RMSE** (Root Mean Squared Error)

### 5ï¸âƒ£ Feature Importance Visualization
- Plotted the top important features using a horizontal bar chart

### 6ï¸âƒ£ (Optional) XGBoost Model
- Trained a simple `XGBRegressor`
- Compared RÂ² score with Random Forest

---

## ğŸ“Š Evaluation Metrics

### âœ… RÂ² Score
- Measures how well the model explains variance in the target
- Higher is better

### âœ… RMSE
- Measures average prediction error
- Lower is better

---

## ğŸ“ˆ Output

The notebook produces:
- Random Forest RÂ² Score and RMSE
- Feature Importance Graph
- (Optional) XGBoost RÂ² Score

---

## â–¶ï¸ How to Run

### 1. Install dependencies
```bash
pip install pandas numpy matplotlib scikit-learn
```

(Optional for XGBoost)

```bash
pip install xgboost
```

### 2. Run the notebook

Open and run:

* `assignment_3.ipynb`

---

## ğŸ“Œ Conclusion

Random Forest performs better than basic models in most cases because it:

* handles non-linear patterns
* reduces overfitting using multiple trees
* provides feature importance for interpretation

---

## ğŸ“Œ Author

**Shaik Ansar**
AI/ML Intern @ Cepia Labs
---