# ğŸ“˜ Week 4 â€“ Day 4 Assignment  
## Random Forest & Logistic Regression with Cross-Validation  
ğŸ“… Date: 13-02-2026  
ğŸ“Š Dataset: Spam Email Classifier (Kaggle)  
ğŸ§  Problem Type: Supervised Machine Learning (Classification)

---

## ğŸ¯ Objective

The objective of this assignment is to:

- Train Logistic Regression and Random Forest models
- Perform 10-Fold Cross-Validation
- Compare performance metrics
- Evaluate model stability
- Analyze generalization ability
- Compare results and draw insights

---

## ğŸ“Š Dataset Information

**Source:** Kaggle  
**url:** https://www.kaggle.com/datasets/abdallahwagih/spam-emails
**Dataset:** Spam Email Dataset  

**Features:**
- `Category` â†’ ham / spam
- `Message` â†’ Email text

**Target Variable:**
- Ham â†’ 0  
- Spam â†’ 1  

Total Records: 5572

---

## ğŸ› ï¸ Technologies Used

- Python
- Pandas
- NumPy
- Scikit-learn
- Matplotlib
- Jupyter Notebook

---

## ğŸ§© Steps Performed

### 1ï¸âƒ£ Data Preprocessing

- Loaded dataset using Pandas
- Converted labels (ham/spam) into numeric values
- Checked class distribution
- Split dataset into training and testing sets
- Applied TF-IDF vectorization for text processing

---

### 2ï¸âƒ£ Model Training

Trained two models:

- Logistic Regression
- Random Forest Classifier

Used Pipeline to combine TF-IDF and model training.

---

### 3ï¸âƒ£ Cross-Validation

- Applied 10-Fold Cross-Validation
- Evaluated using:
  - Accuracy
  - Precision
  - Recall
  - F1 Score
- Calculated Standard Deviation for stability analysis

---

### 4ï¸âƒ£ Model Evaluation

Evaluated models on test dataset using:

- Accuracy Score
- F1 Score
- Classification Report
- Confusion Matrix

Compared Cross-Validation results with Test results.

---

## ğŸ“ˆ Evaluation Metrics

| Metric Used | Purpose |
|-------------|----------|
| Accuracy | Overall correctness |
| Precision | Spam prediction correctness |
| Recall | Spam detection ability |
| F1 Score | Balance between Precision & Recall |

Primary Metric: **F1 Score**

---

## ğŸ” Observations

- Logistic Regression performed slightly better for text classification.
- Random Forest showed strong performance but slightly higher variance.
- Cross-validation provided reliable performance estimation.
- Lower standard deviation indicates better model stability.
- Test accuracy was close to cross-validation accuracy, indicating good generalization.

---

## ğŸ§  Conclusion

This assignment demonstrated:

- Implementation of ensemble and linear models.
- Importance of cross-validation in evaluating stability.
- Comparison of multiple performance metrics.
- Understanding of generalization and model performance.

### Key Learnings:

- Cross-validation improves reliability.
- Logistic Regression works efficiently for text classification.
- Random Forest is powerful but may slightly overfit.
- F1 Score is important for classification problems.

---

## ğŸ“Œ Final Note

This assignment strengthened understanding of:

- Cross-validation
- Model comparison
- Stability analysis
- Generalization evaluation
- Performance metrics in classification
