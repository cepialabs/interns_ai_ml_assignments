
# ğŸ“§ Logistic Regression and Random Forest for Spam Email Classification

**ğŸ“… Date:** 13 February 2026

---

## ğŸ“Œ Project Overview

This project focuses on building and evaluating **spam email classification models** using **Logistic Regression** and **Random Forest**.
The models are compared using **5-fold and 10-fold Cross-Validation** to analyze **performance, stability, and generalization**.

---

## ğŸ“Š Dataset

* **Dataset Name:** Spam Assassin Email Classification Dataset
* **Source:** Kaggle
* **Dataset Link:**
  ğŸ‘‰ [https://www.kaggle.com/datasets/ganiyuolalekan/spam-assassin-email-classification-dataset](https://www.kaggle.com/datasets/ganiyuolalekan/spam-assassin-email-classification-dataset)

### Dataset Description

* `text` â†’ Email content

* `target` â†’ Label

  * `0` = Ham (Not Spam)
  * `1` = Spam

* **Problem Type:** Binary Classification

* **Data Type:** Text data (emails)

---

## âš™ï¸ Technologies Used

* **Programming Language:** Python
* **Libraries:**

  * pandas
  * numpy
  * scikit-learn
  * matplotlib

---

## ğŸ”„ Methodology

### 1ï¸âƒ£ Data Preprocessing

* Removed rows with missing values
* Ensured correct data types
* Converted email text into numerical features using **TF-IDF**

### 2ï¸âƒ£ Models Implemented

* **Logistic Regression** â€“ baseline linear classifier
* **Random Forest Classifier** â€“ ensemble-based non-linear model

### 3ï¸âƒ£ Cross-Validation Strategy

* **5-Fold Stratified Cross-Validation**
* **10-Fold Stratified Cross-Validation**
* Stratification ensures balanced spam/ham distribution in each fold

### 4ï¸âƒ£ Evaluation Metrics

* Accuracy
* Precision
* Recall
* F1-score

---

## ğŸ“ˆ Results & Analysis

### ğŸ”¹ Performance Comparison

* Random Forest achieved higher overall performance
* Logistic Regression provided strong baseline results

### ğŸ”¹ Model Stability

* Logistic Regression showed lower variance across folds
* Random Forest variance decreased with 10-fold cross-validation

### ğŸ”¹ Generalization

* 10-fold CV produced more reliable performance estimates
* Random Forest benefited more from increased training data

---

## ğŸ“Š Visualization

* Bar chart comparing **F1-score standard deviation**
* Used to analyze **model stability and consistency**

---

## âœ… Conclusion

* **Best Performing Model:** Random Forest
* **Most Stable Model:** Logistic Regression
* **Best Evaluation Strategy:** 10-Fold Cross-Validation

Random Forest with 10-fold cross-validation offers the best balance between performance and generalization, while Logistic Regression serves as a strong and interpretable baseline.


---

