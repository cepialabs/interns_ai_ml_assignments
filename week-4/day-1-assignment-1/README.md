---
# ğŸ¡ House Prices Feature Engineering & Feature Importance

## ğŸ“Œ Project Overview

This project focuses on **feature engineering** and **feature importance analysis** for a house price dataset.

The goal is to:

* Extract meaningful features from raw data (example: **House Age** from Year Built)
* Create new pricing-based features (example: **Price per Square Foot**)
* Encode categorical variables (example: city, state, property type)
* Train machine learning models and analyze which features influence house prices the most

---

## ğŸ“‚ Dataset Information

The dataset used in this project is:

âœ… **`data.csv`**

### Key Columns Used

| Column         | Description                                  |
| -------------- | -------------------------------------------- |
| `target`       | House price (as string, ex: `$418,000`)      |
| `sqft`         | House size in square feet (ex: `1,947 sqft`) |
| `beds`         | Bedrooms (ex: `3 Beds`)                      |
| `baths`        | Bathrooms (ex: `3 Baths`)                    |
| `homeFacts`    | Contains Year Built information              |
| `city`         | City name                                    |
| `state`        | State name                                   |
| `propertyType` | Type of property                             |

---

## ğŸ¯ Assignment Tasks Completed

### âœ… 1. Extract House Age

Year Built is stored inside the `homeFacts` column as a nested dictionary-like structure.

We extract `YearBuilt` and compute:

HouseAge = CurrentYear - YearBuilt

---

### âœ… 2. Create Price per Square Foot

PricePerSqFt = \frac{Price}{SqFt}

This feature helps normalize prices across houses of different sizes.

---

### âœ… 3. Encode Categorical Features

Categorical features such as:

* `city`
* `state`
* `propertyType`
* `status`
* `fireplace`

are encoded using:

âœ… **OneHotEncoder** (from Scikit-learn)

---

### âœ… 4. Feature Importance Analysis

We trained models to identify which features impact house prices the most.

Models used:

* **Ridge Regression** (baseline)
* **Random Forest Regressor** (for feature importance)

Random Forest provides:

âœ… `feature_importances_`

---

## ğŸ§  Machine Learning Workflow

### Steps Followed:

1. Load dataset (`data.csv`)
2. Clean price and sqft columns
3. Extract YearBuilt from `homeFacts`
4. Feature engineering:

   * HouseAge
   * PricePerSqFt
5. Handle missing values
6. Encode categorical columns
7. Train Ridge Regression
8. Train Random Forest
9. Extract and save feature importance

---

## âš™ï¸ Technologies Used

* Python 3.x
* Pandas
* NumPy
* Scikit-learn

---

## ğŸ“Œ Installation

Install required libraries:

```bash
pip install pandas numpy scikit-learn
```

---

## â–¶ï¸ How to Run the Project

### Option 1: Run Python Script

Make sure `data.csv` is in the same folder.

```bash
python main.py
```

### Option 2: Run in Jupyter Notebook

Open notebook:

```bash
jupyter notebook
```

Then run the cells.

---

## ğŸ“Š Output Generated

### âœ… Model Evaluation Metrics

* MAE (Mean Absolute Error)
* RÂ² Score

### âœ… Feature Importance File

A file is generated:

ğŸ“„ **`feature_importance.csv`**

It contains:

* Feature name
* Importance score

Example:

| Feature  | Importance |
| -------- | ---------- |
| SqFt     | 0.31       |
| HouseAge | 0.19       |
| Beds     | 0.12       |

---

## ğŸ”¥ Key Results (Expected)

From feature importance, the most important features generally include:

* `SqFt`
* `HouseAge`
* `Beds`
* `Baths`
* `state`
* `city`
* `propertyType`

---

## ğŸ“ Project Structure

```
House-Price-Feature-Engineering/
â”‚
â”œâ”€â”€ data.csv
â”œâ”€â”€ assignment-1.ipynb
â”œâ”€â”€ feature_importance.csv
â”œâ”€â”€ README.md
â””â”€â”€ main.py (optional)
```

---

## âœ… Conclusion

This project successfully demonstrates:

* Feature extraction from raw data (`homeFacts`)
* Creation of new meaningful numerical features
* Encoding of categorical variables
* Model training for prediction
* Feature importance analysis using tree models

---

## ğŸ‘¤ Author

**Krushna Chandra Bindhani**

---
