# Week 3 Day 3 Assignment  
Date: 06-02-2026

## Title  
Classification using Decision Tree & K-Nearest Neighbors (KNN) â€“ From Scratch

---

## Dataset Resource  
Kaggle Dataset  
**URL** https://www.kaggle.com/datasets/nitishabharathi/email-spam-dataset

---

## Objective  
The objective of this assignment is to understand how classification algorithms work internally by implementing them from scratch using the sklearn library.

This assignment focuses on:
- Decision Tree Classification  
- K-Nearest Neighbors (KNN) Classification  

---

## Problem 1: Decision Tree Classification  

### Description  
In this task, a simple Decision Tree classifier is implemented to predict class labels based on feature values using rule-based splitting.

### Methodology  
- Data preprocessing  
- Feature selection  
- Splitting data using threshold conditions  
- Predicting output class labels  
- Handling errors such as empty features and undefined trees  

### Output  
The model predicts the class labels for test data using decision rules.

---

## Problem 2: K-Nearest Neighbors (KNN) Classification  

### Description  
This task classifies data points by finding the K nearest neighbors based on distance and assigning the majority class.

### Methodology  
- Feature normalization  
- Euclidean distance calculation  
- Selection of K nearest neighbors  
- Majority voting for class prediction  
- Manual accuracy calculation  

### Output  
The model predicts class labels and computes accuracy without using sklearn.

---

## Technologies Used  
- Python  
- NumPy  
- Pandas  
- Jupyter Notebook  

---

## Learning Outcomes  
Through this assignment, I learned:
- How decision trees make predictions using rules  
- How distance-based algorithms like KNN work  
- Manual prediction and accuracy calculation  
- Importance of data preprocessing  
- Internal working of ML algorithms without external libraries  

---

## Conclusion  
This assignment helped me gain a deeper understanding of classification algorithms by implementing Decision Tree and KNN from scratch. It improved my confidence in building machine learning models without relying on predefined libraries.
